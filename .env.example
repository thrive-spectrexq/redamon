# =============================================================================
# RedAmon — Environment Configuration
# =============================================================================
# Copy this file to .env and fill in at least one AI provider key.
#   cp .env.example .env
#
# All values below have sane defaults — you only NEED to set an AI key.
# =============================================================================

# ---------------------------------------------------------------------------
# AI Provider Keys (at least one required)
# ---------------------------------------------------------------------------
ANTHROPIC_API_KEY=              # recommended
OPENAI_API_KEY=

# ---------------------------------------------------------------------------
# Additional AI Providers (optional)
# ---------------------------------------------------------------------------
OPENAI_COMPAT_BASE_URL=          # Any OpenAI-compatible endpoint (/v1/chat/completions + /v1/models)
OPENAI_COMPAT_API_KEY=           # Optional; if empty, agent sends fallback token "ollama"
                                 #
                                 # Supported backends (example URLs):
                                 #   Ollama            → http://host.docker.internal:11434/v1
                                 #   vLLM              → http://host.docker.internal:8000/v1
                                 #   LM Studio         → http://host.docker.internal:1234/v1
                                 #   LocalAI           → http://host.docker.internal:8080/v1
                                 #   Jan               → http://host.docker.internal:1337/v1
                                 #   llama.cpp server  → http://host.docker.internal:8080/v1
                                 #   LiteLLM proxy     → http://host.docker.internal:4000/v1
                                 #   Together AI       → https://api.together.xyz/v1
                                 #   Groq              → https://api.groq.com/openai/v1
                                 #   Fireworks AI      → https://api.fireworks.ai/inference/v1
                                 #   Mistral AI        → https://api.mistral.ai/v1
                                 #   Deepinfra         → https://api.deepinfra.com/v1/openai
OPENROUTER_API_KEY=             # OpenRouter (multi-model gateway)
AWS_ACCESS_KEY_ID=              # AWS Bedrock
AWS_SECRET_ACCESS_KEY=          # AWS Bedrock
AWS_DEFAULT_REGION=us-east-1    # AWS Bedrock region

# ---------------------------------------------------------------------------
# Optional API Keys
# ---------------------------------------------------------------------------
TAVILY_API_KEY=                 # web search for AI agent
NVD_API_KEY=                    # NIST NVD (higher rate limits for vuln lookups)
